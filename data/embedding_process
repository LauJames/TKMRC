# step 1
git clone https://github.com/stanfordnlp/GloVe glove\

# step 2
make -C glove/

# step 3
ls glove/build/

# step 4
- 需要修改文件路径
python3 gen_corpus.py

# step 5
- 构建词表vocab(注意参数修改路径)
../../glove/build/vocab_count -verbose 1 -max-vocab 500000 -min-count 1 < ./data/temp/TKMRCcorpus > ./data/temp/vocab.txt

# step 6
- 计算共现矩阵(注意参数修改路径)
../../glove/build/cooccur -verbose 1 -symmetric 0 -window-size 10 -vocab-file ./data/temp/vocab.txt -memory 32.0 -overflow-file ./data/temp/tempoverflow < ./data/temp/MRCcorpus > ./data/temp/cooccurrence.bin

# step 7
- shuffle(注意参数修改路径)
../../glove/build/shuffle -verbose 1 -temp-file ./data/temp/temp -memory 32.0 < ./data/temp/cooccurrence.bin > ./data/temp/cooccurrence.shuf.bin

# step 8
- training word embedding(注意参数修改路径)
../../glove/build/glove -verbose 2 -input-file ./data/temp/cooccurrence.shuf.bin -vocab-file ./data/temp/vocab.txt -save-file ./data/temp/vectors -binary 0 -model 2 -vector-size 200 -threads 12 -alpha 0.75 -x-max 100.0 -eta 0.05 -iter 60

# step 9
- 下载评估程序
bash ./utils/download_thirdparty.sh

# step 10
- 将数据处理成DuReader README.md 所展示的json格式(Raw 数据 + 分词)
python3 TKData/processed_tk.py

# step 11
- 执行百度提出的answer span生成方案，将数据处理成最终可用于机器学习训练的格式
cd ./tf_version
python3 dataset.py

# step 12
- 开始训练数据准备
python3 run.py --prepare

# step 13
- train
python3 run.py --train

...